
@article{zhao_drug_2016,
	title = {Drug drug interaction extraction from biomedical literature using syntax convolutional neural network},
	issn = {1367-4803, 1460-2059},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btw486},
	doi = {10.1093/bioinformatics/btw486},
	pages = {btw486},
	journaltitle = {Bioinformatics},
	author = {Zhao, Zhehuan and Yang, Zhihao and Luo, Ling and Lin, Hongfei and Wang, Jian},
	urldate = {2018-05-28},
	date = {2016-07-27},
	langid = {english},
	file = {Supplementary_Materials.pdf:/Users/andrewshi/Zotero/storage/LQASGSQY/Supplementary_Materials.pdf:application/pdf;Zhao et al. - 2016 - Drug drug interaction extraction from biomedical l.pdf:/Users/andrewshi/Zotero/storage/IZZ48VAC/Zhao et al. - 2016 - Drug drug interaction extraction from biomedical l.pdf:application/pdf}
}

@article{sahu_drug-drug_2017,
	title = {Drug-Drug Interaction Extraction from Biomedical Text Using Long Short Term Memory Network},
	url = {http://arxiv.org/abs/1701.08303},
	abstract = {Simultaneous administration of multiple drugs can have synergistic or antagonistic effects as one drug can affect activities of other drugs. Synergistic effects lead to improved therapeutic outcomes, whereas, antagonistic effects can be life-threatening, may lead to increased healthcare cost, or may even cause death. Thus identification of unknown drug-drug interaction ({DDI}) is an important concern for efficient and effective healthcare. Although multiple resources for {DDI} exist, they are often unable to keep pace with rich amount of information available in fast growing biomedical texts. Most existing methods model {DDI} extraction from text as a classification problem and mainly rely on handcrafted features. Some of these features further depend on domain specific tools. Recently neural network models using latent features have been shown to give similar or better performance than the other existing models dependent on handcrafted features. In this paper, we present three models namely, \{{\textbackslash}it B-{LSTM}\}, \{{\textbackslash}it {AB}-{LSTM}\} and \{{\textbackslash}it Joint {AB}-{LSTM}\} based on long short-term memory ({LSTM}) network. All three models utilize word and position embedding as latent features and thus do not rely on explicit feature engineering. Further use of bidirectional long short-term memory (Bi-{LSTM}) networks allow implicit feature extraction from the whole sentence. The two models, \{{\textbackslash}it {AB}-{LSTM}\} and \{{\textbackslash}it Joint {AB}-{LSTM}\} also use attentive pooling in the output of Bi-{LSTM} layer to assign weights to features. Our experimental results on the {SemEval}-2013 {DDI} extraction dataset show that the \{{\textbackslash}it Joint {AB}-{LSTM}\} model outperforms all the existing methods, including those relying on handcrafted features. The other two proposed {LSTM} models also perform competitively with state-of-the-art methods.},
	journaltitle = {{arXiv}:1701.08303 [cs]},
	author = {Sahu, Sunil Kumar and Anand, Ashish},
	urldate = {2018-05-28},
	date = {2017-01-28},
	eprinttype = {arxiv},
	eprint = {1701.08303},
	file = {arXiv\:1701.08303 PDF:/Users/andrewshi/Zotero/storage/ZQ5A3YMY/Sahu and Anand - 2017 - Drug-Drug Interaction Extraction from Biomedical T.pdf:application/pdf;arXiv.org Snapshot:/Users/andrewshi/Zotero/storage/3HMUVB5I/1701.html:text/html}
}

@article{lin_structured_2017,
	title = {A Structured Self-attentive Sentence Embedding},
	url = {http://arxiv.org/abs/1703.03130},
	abstract = {This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.},
	journaltitle = {{arXiv}:1703.03130 [cs]},
	author = {Lin, Zhouhan and Feng, Minwei and Santos, Cicero Nogueira dos and Yu, Mo and Xiang, Bing and Zhou, Bowen and Bengio, Yoshua},
	urldate = {2018-06-23},
	date = {2017-03-08},
	eprinttype = {arxiv},
	eprint = {1703.03130},
	file = {arXiv.org Snapshot:/Users/andrewshi/Zotero/storage/WBVCIVLY/1703.html:text/html;Lin et al. - 2017 - A Structured Self-attentive Sentence Embedding.pdf:/Users/andrewshi/Zotero/storage/G6RTCEAF/Lin et al. - 2017 - A Structured Self-attentive Sentence Embedding.pdf:application/pdf}
}

@article{shen_disan:_2017,
	title = {{DiSAN}: Directional Self-Attention Network for {RNN}/{CNN}-Free Language Understanding},
	url = {http://arxiv.org/abs/1709.04696},
	shorttitle = {{DiSAN}},
	abstract = {Recurrent neural nets ({RNN}) and convolutional neural nets ({CNN}) are widely used on {NLP} tasks to capture the long-term and local dependencies, respectively. Attention mechanisms have recently attracted enormous interest due to their highly parallelizable computation, significantly less training time, and flexibility in modeling dependencies. We propose a novel attention mechanism in which the attention between elements from input sequence(s) is directional and multi-dimensional (i.e., feature-wise). A light-weight neural net, "Directional Self-Attention Network ({DiSAN})", is then proposed to learn sentence embedding, based solely on the proposed attention without any {RNN}/{CNN} structure. {DiSAN} is only composed of a directional self-attention with temporal order encoded, followed by a multi-dimensional attention that compresses the sequence into a vector representation. Despite its simple form, {DiSAN} outperforms complicated {RNN} models on both prediction quality and time efficiency. It achieves the best test accuracy among all sentence encoding methods and improves the most recent best result by 1.02\% on the Stanford Natural Language Inference ({SNLI}) dataset, and shows state-of-the-art test accuracy on the Stanford Sentiment Treebank ({SST}), Multi-Genre natural language inference ({MultiNLI}), Sentences Involving Compositional Knowledge ({SICK}), Customer Review, {MPQA}, {TREC} question-type classification and Subjectivity ({SUBJ}) datasets.},
	journaltitle = {{arXiv}:1709.04696 [cs]},
	author = {Shen, Tao and Zhou, Tianyi and Long, Guodong and Jiang, Jing and Pan, Shirui and Zhang, Chengqi},
	urldate = {2018-06-27},
	date = {2017-09-14},
	eprinttype = {arxiv},
	eprint = {1709.04696},
	file = {arXiv.org Snapshot:/Users/andrewshi/Zotero/storage/L7BBX9B3/1709.html:text/html;Shen et al. - 2017 - DiSAN Directional Self-Attention Network for RNN.pdf:/Users/andrewshi/Zotero/storage/XE7ZAXKI/Shen et al. - 2017 - DiSAN Directional Self-Attention Network for RNN.pdf:application/pdf}
}

@inproceedings{le_distributed_2014,
	title = {Distributed representations of sentences and documents},
	eventtitle = {International Conference on Machine Learning},
	pages = {1188--1196},
	author = {Le, Quoc and Mikolov, Tomas},
	date = {2014},
	file = {Le and Mikolov - 2014 - Distributed representations of sentences and docum.pdf:/Users/andrewshi/Zotero/storage/88JP33HR/Le and Mikolov - 2014 - Distributed representations of sentences and docum.pdf:application/pdf}
}

@article{mikolov_efficient_2013,
	title = {Efficient Estimation of Word Representations in Vector Space},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	journaltitle = {{arXiv}:1301.3781 [cs]},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	urldate = {2018-08-01},
	date = {2013-01-16},
	eprinttype = {arxiv},
	eprint = {1301.3781},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1301.3781 PDF:/Users/andrewshi/Zotero/storage/XGRCYEP8/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf;arXiv.org Snapshot:/Users/andrewshi/Zotero/storage/3VJJT7KI/1301.html:text/html}
}

@article{mikolov_distributed_2013,
	title = {Distributed Representations of Words and Phrases and their Compositionality},
	url = {http://arxiv.org/abs/1310.4546},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	journaltitle = {{arXiv}:1310.4546 [cs, stat]},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	urldate = {2018-08-01},
	date = {2013-10-16},
	eprinttype = {arxiv},
	eprint = {1310.4546},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1310.4546 PDF:/Users/andrewshi/Zotero/storage/XA5WJELB/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases a.pdf:application/pdf;arXiv.org Snapshot:/Users/andrewshi/Zotero/storage/6L9EBZR6/1310.html:text/html}
}

@article{jiao_chinese_2018,
	title = {Chinese Lexical Analysis with Deep Bi-{GRU}-{CRF} Network},
	url = {http://arxiv.org/abs/1807.01882},
	abstract = {Lexical analysis is believed to be a crucial step towards natural language understanding and has been widely studied. Recent years, end-to-end lexical analysis models with recurrent neural networks have gained increasing attention. In this report, we introduce a deep Bi-{GRU}-{CRF} network that jointly models word segmentation, part-of-speech tagging and named entity recognition tasks. We trained the model using several massive corpus pre-tagged by our best Chinese lexical analysis tool, together with a small, yet high-quality human annotated corpus. We conducted balanced sampling between different corpora to guarantee the influence of human annotations, and fine-tune the {CRF} decoding layer regularly during the training progress. As evaluated by linguistic experts, the model achieved a 95.5\% accuracy on the test set, roughly 13\% relative error reduction over our (previously) best Chinese lexical analysis tool. The model is computationally efficient, achieving the speed of 2.3K characters per second with one thread.},
	journaltitle = {{arXiv}:1807.01882 [cs]},
	author = {Jiao, Zhenyu and Sun, Shuqi and Sun, Ke},
	urldate = {2018-08-01},
	date = {2018-07-05},
	eprinttype = {arxiv},
	eprint = {1807.01882},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1807.01882 PDF:/Users/andrewshi/Zotero/storage/DU3I48VR/Jiao et al. - 2018 - Chinese Lexical Analysis with Deep Bi-GRU-CRF Netw.pdf:application/pdf;arXiv.org Snapshot:/Users/andrewshi/Zotero/storage/WV55BS8E/1807.html:text/html}
}

@article{vaswani_attention_2017,
	title = {Attention Is All You Need},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	journaltitle = {{arXiv}:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	urldate = {2018-08-01},
	date = {2017-06-12},
	eprinttype = {arxiv},
	eprint = {1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/andrewshi/Zotero/storage/LMTVQY2T/1706.html:text/html;Vaswani et al. - 2017 - Attention Is All You Need.pdf:/Users/andrewshi/Zotero/storage/TGHNZ2F3/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf}
}

@article{segura-bedmar_lessons_2014,
	title = {Lessons learnt from the {DDIExtraction}-2013 Shared Task},
	volume = {51},
	issn = {15320464},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1532046414001245},
	doi = {10.1016/j.jbi.2014.05.007},
	pages = {152--164},
	journaltitle = {Journal of Biomedical Informatics},
	author = {Segura-Bedmar, Isabel and Martínez, Paloma and Herrero-Zazo, María},
	urldate = {2018-08-10},
	date = {2014-10},
	langid = {english},
	file = {Segura-Bedmar et al. - 2014 - Lessons learnt from the DDIExtraction-2013 Shared .pdf:/Users/andrewshi/Zotero/storage/7PMWVKDM/Segura-Bedmar et al. - 2014 - Lessons learnt from the DDIExtraction-2013 Shared .pdf:application/pdf}
}

@inproceedings{chowdhury_fbk-irst:_2013,
	title = {{FBK}-irst: a multi-phase kernel based approach for drug-drug interaction detection and classification that exploits linguistic information},
	volume = {2},
	eventtitle = {Second Joint Conference on Lexical and Computational Semantics (* {SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({SemEval} 2013)},
	pages = {351--355},
	author = {Chowdhury, Md Faisal Mahbub and Lavelli, Alberto},
	date = {2013},
	file = {Chowdhury and Lavelli - 2013 - FBK-irst a multi-phase kernel based approach for .pdf:/Users/andrewshi/Zotero/storage/CGLZRLTI/Chowdhury and Lavelli - 2013 - FBK-irst a multi-phase kernel based approach for .pdf:application/pdf}
}

@inproceedings{bjorne_uturku:_2013,
	title = {{UTurku}: drug named entity recognition and drug-drug interaction extraction using {SVM} classification and domain knowledge},
	volume = {2},
	eventtitle = {Second Joint Conference on Lexical and Computational Semantics (* {SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({SemEval} 2013)},
	pages = {651--659},
	author = {Björne, Jari and Kaewphan, Suwisa and Salakoski, Tapio},
	date = {2013},
	file = {Björne et al. - 2013 - UTurku drug named entity recognition and drug-dru.pdf:/Users/andrewshi/Zotero/storage/C6JEZE5W/Björne et al. - 2013 - UTurku drug named entity recognition and drug-dru.pdf:application/pdf}
}

@inproceedings{thomas_wbi-ddi:_2013,
	title = {{WBI}-{DDI}: drug-drug interaction extraction using majority voting},
	volume = {2},
	eventtitle = {Second Joint Conference on Lexical and Computational Semantics (* {SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({SemEval} 2013)},
	pages = {628--635},
	author = {Thomas, Philippe and Neves, Mariana and Rocktäschel, Tim and Leser, Ulf},
	date = {2013},
	file = {Thomas et al. - 2013 - WBI-DDI drug-drug interaction extraction using ma.pdf:/Users/andrewshi/Zotero/storage/3BWB5LKH/Thomas et al. - 2013 - WBI-DDI drug-drug interaction extraction using ma.pdf:application/pdf}
}

@article{kim_extracting_2015,
	title = {Extracting drug–drug interactions from literature using a rich feature-based linear kernel approach},
	volume = {55},
	issn = {1532-0464},
	url = {http://www.sciencedirect.com/science/article/pii/S1532046415000441},
	doi = {10.1016/j.jbi.2015.03.002},
	pages = {23--30},
	journaltitle = {Journal of Biomedical Informatics},
	shortjournal = {Journal of Biomedical Informatics},
	author = {Kim, Sun and Liu, Haibin and Yeganova, Lana and Wilbur, W. John},
	date = {2015-06-01},
	keywords = {Biomedical literature, Drug–drug interaction, Linear kernel approach},
	file = {Kim et al. - 2015 - Extracting drug–drug interactions from literature .pdf:/Users/andrewshi/Zotero/storage/AVGSEW2U/Kim et al. - 2015 - Extracting drug–drug interactions from literature .pdf:application/pdf}
}

@article{de_leo_websites_2006,
	title = {Websites most frequently used by physician for gathering medical information},
	issn = {1942-597X},
	abstract = {Physicians' use of the Internet to gather medical information has increased in recent years. Several studies have been conducted to explore the implications of this use on patient education, the physician-patient relationship, and diagnosis/decision making. In order to better understand the current and future implications of Internet use on patient care activities, it is important to know the Internet sources physicians prefer to consult. The objective of this study was to determine the Internet sources of information physicians most often use to gather medical information. This study demonstrated that the vast majority of physicians indicate they access a targeted site rather than utilize a search engine (such as Google) to gather medical information. Of the targeted site types, most physicians indicate they use 1) edited/secondary data sources as their primary medical information data retrieving, 2) about one quarter of the physicians surveyed indicated research databases which provide access to medical journal publications 3) a minority of physicians use sites dedicated to their specialized area and 4) a small percentage use medical web site portals.},
	pages = {902},
	journaltitle = {{AMIA} ... Annual Symposium proceedings. {AMIA} Symposium},
	shortjournal = {{AMIA} Annu Symp Proc},
	author = {De Leo, G. and {LeRouge}, Cynthia and Ceriani, Claudia and Niederman, Fred},
	date = {2006},
	pmid = {17238521},
	pmcid = {PMC1839616},
	keywords = {Humans, Information Services, Information Storage and Retrieval, Internet, Physicians, Surveys and Questionnaires}
}

@inproceedings{rastegar-mojarad_uwm-triads:_2013,
	title = {{UWM}-{TRIADS}: classifying drug-drug interactions with two-stage {SVM} and post-processing},
	volume = {2},
	eventtitle = {Second Joint Conference on Lexical and Computational Semantics (* {SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({SemEval} 2013)},
	pages = {667--674},
	author = {Rastegar-Mojarad, Majid and Boyce, Richard D and Prasad, Rashmi},
	date = {2013},
	file = {Rastegar-Mojarad et al. - 2013 - UWM-TRIADS classifying drug-drug interactions wit.pdf:/Users/andrewshi/Zotero/storage/DFLDJKFG/Rastegar-Mojarad et al. - 2013 - UWM-TRIADS classifying drug-drug interactions wit.pdf:application/pdf}
}

@article{lopez_insight_2013,
	title = {An insight into classification with imbalanced data: Empirical results and current trends on using data intrinsic characteristics},
	volume = {250},
	issn = {0020-0255},
	pages = {113--141},
	journaltitle = {Information Sciences},
	shortjournal = {Information Sciences},
	author = {López, Victoria and Fernández, Alberto and García, Salvador and Palade, Vasile and Herrera, Francisco},
	date = {2013}
}

@article{liu_drug-drug_2016,
	title = {Drug-drug interaction extraction via convolutional neural networks},
	volume = {2016},
	issn = {1748-670X},
	journaltitle = {Computational and mathematical methods in medicine},
	shortjournal = {Computational and mathematical methods in medicine},
	author = {Liu, Shengyu and Tang, Buzhou and Chen, Qingcai and Wang, Xiaolong},
	date = {2016},
	file = {Liu et al. - 2016 - Drug-drug interaction extraction via convolutional.pdf:/Users/andrewshi/Zotero/storage/BQM6F6US/Liu et al. - 2016 - Drug-drug interaction extraction via convolutional.pdf:application/pdf}
}

@article{tsuruoka_genia_2006,
	title = {{GENIA} tagger: Part-of-speech tagging, shallow parsing, and named entity recognition for biomedical text},
	journaltitle = {Available at: www-tsujii. is. su-tokyo. ac. jp/{GENIA}/tagger},
	shortjournal = {Available at: www-tsujii. is. su-tokyo. ac. jp/{GENIA}/tagger},
	author = {Tsuruoka, Y},
	date = {2006}
}

@inproceedings{rehurek_software_2010,
	location = {Valletta, Malta},
	title = {Software Framework for Topic Modelling with Large Corpora},
	pages = {45--50},
	booktitle = {Proceedings of the {LREC} 2010 Workshop on New Challenges for {NLP} Frameworks},
	publisher = {{ELRA}},
	author = {Řehůřek, Radim and Sojka, Petr},
	date = {2010-05}
}

@inproceedings{de_vine_medical_2014,
	title = {Medical semantic similarity with a neural language model},
	isbn = {1-4503-2598-X},
	eventtitle = {Proceedings of the 23rd {ACM} international conference on conference on information and knowledge management},
	pages = {1819--1822},
	publisher = {{ACM}},
	author = {De Vine, Lance and Zuccon, Guido and Koopman, Bevan and Sitbon, Laurianne and Bruza, Peter},
	date = {2014}
}

@article{aronson_overview_2010,
	title = {An overview of {MetaMap}: historical perspective and recent advances},
	volume = {17},
	issn = {1527-974X},
	pages = {229--236},
	number = {3},
	journaltitle = {Journal of the American Medical Informatics Association},
	shortjournal = {Journal of the American Medical Informatics Association},
	author = {Aronson, Alan R and Lang, François-Michel},
	date = {2010}
}

@article{bodenreider_unified_2004,
	title = {The unified medical language system ({UMLS}): integrating biomedical terminology},
	volume = {32},
	issn = {0305-1048},
	pages = {D267--D270},
	issue = {suppl\_1},
	journaltitle = {Nucleic acids research},
	shortjournal = {Nucleic acids research},
	author = {Bodenreider, Olivier},
	date = {2004}
}

@article{hochreiter_long_1997,
	title = {Long short-term memory},
	volume = {9},
	issn = {0899-7667},
	pages = {1735--1780},
	number = {8},
	journaltitle = {Neural computation},
	shortjournal = {Neural computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	date = {1997}
}

@article{schuster_bidirectional_1997,
	title = {Bidirectional recurrent neural networks},
	volume = {45},
	issn = {1053-587X},
	pages = {2673--2681},
	number = {11},
	journaltitle = {{IEEE} Transactions on Signal Processing},
	shortjournal = {{IEEE} Transactions on Signal Processing},
	author = {Schuster, Mike and Paliwal, Kuldip K},
	date = {1997}
}

@article{sak_long_2014,
	title = {Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition},
	journaltitle = {{arXiv} preprint {arXiv}:1402.1128},
	shortjournal = {{arXiv} preprint {arXiv}:1402.1128},
	author = {Sak, Haşim and Senior, Andrew and Beaufays, Françoise},
	date = {2014}
}

@article{huang_bidirectional_2015,
	title = {Bidirectional {LSTM}-{CRF} models for sequence tagging},
	journaltitle = {{arXiv} preprint {arXiv}:1508.01991},
	shortjournal = {{arXiv} preprint {arXiv}:1508.01991},
	author = {Huang, Zhiheng and Xu, Wei and Yu, Kai},
	date = {2015}
}

@article{feng_language-independent_2018,
	title = {A language-independent neural network for event detection},
	volume = {61},
	issn = {1674-733X},
	pages = {092106},
	number = {9},
	journaltitle = {Science China Information Sciences},
	shortjournal = {Science China Information Sciences},
	author = {Feng, Xiaocheng and Qin, Bing and Liu, Ting},
	date = {2018}
}

@article{kiperwasser_simple_2016,
	title = {Simple and accurate dependency parsing using bidirectional {LSTM} feature representations},
	journaltitle = {{arXiv} preprint {arXiv}:1603.04351},
	shortjournal = {{arXiv} preprint {arXiv}:1603.04351},
	author = {Kiperwasser, Eliyahu and Goldberg, Yoav},
	date = {2016}
}

@article{krumm_user-generated_2008,
	title = {User-generated content},
	volume = {7},
	issn = {1536-1268},
	pages = {10--11},
	number = {4},
	journaltitle = {{IEEE} Pervasive Computing},
	shortjournal = {{IEEE} Pervasive Computing},
	author = {Krumm, John and Davies, Nigel and Narayanaswami, Chandra},
	date = {2008}
}

@inproceedings{duan_mining_2013,
	title = {Mining online user-generated content: using sentiment analysis technique to study hotel service quality},
	isbn = {1-4673-5933-5},
	eventtitle = {System Sciences ({HICSS}), 2013 46th Hawaii International Conference on},
	pages = {3119--3128},
	publisher = {{IEEE}},
	author = {Duan, Wenjing and Cao, Qing and Yu, Yang and Levy, Stuart},
	date = {2013}
}

@inproceedings{segura-bedmar_semeval-2013_2013,
	title = {Semeval-2013 task 9: Extraction of drug-drug interactions from biomedical texts (ddiextraction 2013)},
	volume = {2},
	eventtitle = {Second Joint Conference on Lexical and Computational Semantics (* {SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({SemEval} 2013)},
	pages = {341--350},
	author = {Segura-Bedmar, Isabel and Martínez, Paloma and Zazo, María Herrero},
	date = {2013}
}

@article{chollet_keras_2015,
	title = {Keras},
	author = {Chollet, François},
	date = {2015}
}

@article{girija_tensorflow:_2016,
	title = {Tensorflow: Large-scale machine learning on heterogeneous distributed systems},
	author = {Girija, Sanjay Surendranath},
	date = {2016}
}

@inproceedings{ng_feature_2004,
	title = {Feature selection, L 1 vs. L 2 regularization, and rotational invariance},
	isbn = {1-58113-838-5},
	eventtitle = {Proceedings of the twenty-first international conference on Machine learning},
	pages = {78},
	publisher = {{ACM}},
	author = {Ng, Andrew Y},
	date = {2004}
}

@article{kingma_adam:_2014,
	title = {Adam: A Method for Stochastic Optimization},
	url = {http://arxiv.org/abs/1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	journaltitle = {{arXiv}:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2018-08-26},
	date = {2014-12-22},
	eprinttype = {arxiv},
	eprint = {1412.6980},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv\:1412.6980 PDF:/Users/andrewshi/Zotero/storage/SRXTZ3AV/Kingma and Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/andrewshi/Zotero/storage/KIJQKIL5/1412.html:text/html}
}

@inproceedings{liu_dependency-based_2016,
	title = {Dependency-based convolutional neural network for drug-drug interaction extraction},
	isbn = {1-5090-1611-2},
	eventtitle = {Bioinformatics and Biomedicine ({BIBM}), 2016 {IEEE} International Conference on},
	pages = {1074--1080},
	publisher = {{IEEE}},
	author = {Liu, Shengyu and Chen, Kai and Chen, Qingcai and Tang, Buzhou},
	date = {2016}
}

@inproceedings{moen_distributional_2013,
	title = {Distributional semantics resources for biomedical text processing},
	eventtitle = {Proceedings of the 5th International Symposium on Languages in Biology and Medicine, Tokyo, Japan},
	pages = {39--43},
	author = {Moen, {SPFGH} and Ananiadou, Tapio Salakoski2 Sophia},
	date = {2013}
}

@article{wang_ontology-based_2017,
	title = {Ontology-based systematical representation and drug class effect analysis of package insert-reported adverse events associated with cardiovascular drugs used in China},
	volume = {7},
	issn = {2045-2322},
	doi = {10.1038/s41598-017-12580-4},
	abstract = {With increased usage of cardiovascular drugs ({CVDs}) for treating cardiovascular diseases, it is important to analyze {CVD}-associated adverse events ({AEs}). In this study, we systematically collected package insert-reported {AEs} associated with {CVDs} used in China, and developed and analyzed an Ontology of Cardiovascular Drug {AEs} ({OCVDAE}). Extending the Ontology of {AEs} ({OAE}) and {NDF}-{RT}, {OCVDAE} includes 194 {CVDs}, {CVD} ingredients, mechanisms of actions ({MoAs}), and {CVD}-associated 736 {AEs}. An {AE}-specific drug class effect is defined to exist when all the drugs (drug chemical ingredients or drug products) in a drug class are associated with an {AE}, which is formulated as a new proportional class level ratio ("{PCR}") = 1. Our {PCR}-based heatmap analysis identified many class level drug effects on different {AE} classes such as behavioral and neurological {AE} and digestive system {AE}. Additional drug-{AE} correlation tests (i.e., class-level {PRR}, Chi-squared, and minimal case reports) were also modified and applied to further detect statistically significant drug class effects. Two drug ingredient classes and three {CVD} {MoA} classes were found to have statistically significant class effects on 13 {AEs}. For example, the {CVD} Active Transporter Interactions class (including reserpine, indapamide, digoxin, and deslanoside) has statistically significant class effect on anorexia and diarrhea {AEs}.},
	pages = {13819},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Wang, Liwei and Li, Mei and Xie, Jiangan and Cao, Yuying and Liu, Hongfang and He, Yongqun},
	date = {2017-10-23},
	pmid = {29061976},
	pmcid = {PMC5653862}
}